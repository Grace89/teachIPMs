nlsncljdnslv
install.packages(c('reshape','rjags','R2jags','MCMCpack','runjags','bayesm','vegan','ecodist','grid','boot','plotrix','Hmisc','msm','spBayes'),dep=T)#
install.packages(c('assist','fields','BSDA','RColorBrewer'),dep=T)#
install.packages(c('spatstat','grDevices','ks','foreign','MASS','maptools','TeachingDemos'),dep=T)#
install.packages(c('FD','ape'),dep=T)#
install.packages(c('MCMCglmm','arm','lme4'),dep=T)#
#
install.packages(c('bayesDem','bayespack','LearnBayes','MasterBayes','MCMCpack'),dep=T)#
#
install.packages(c('maxlike','SDMTools','flexmix','ResourceSelection'),dep=T)#
#
#setRepositories(ind=1:2)#
#install.packages('rgdal',type='source')#
install.packages('rgdal',repos="http://www.stats.ox.ac.uk/pub/RWin")#
#
install.packages('doBy',dep=T)#
# for eclipse#
install.packages(c("knitr"),dep=T)#
install.packages(c("rj", "rj.gd"), repos="http://download.walware.de/rj-1.1")#
install.packages("rJava")#
#
install.packages(c('MuMIn','ez','gplots'),dep=T) #
install.packages('IPMpack',dep=T) # may have to get ipmpack from binary#
#
install.packages(c('randomForest','biomod2','gbm','mda'),dep=T)#
install.packages(c('maxLik','subplex'),dep=T)#
install.packages(c('xtable','dismo'),dep=T)#
install.packages(c('hSDM'),dep=T)#
#
install.packages(c('MuMIn','lme4','ez'),dep=T)#
#
install.packages(c('rv','compositions'),dep=T)#
#
install.packages(c('raster','doMC','foreach'),dep=T)#
#
install.packages('doSNOW',dep=T)#
# in terminal: R CMD INSTALL Downloads/hSDM_1-1.0.tar (an updated version from ghislain? this is missing)#
#
install.packages(c('nleqslv','distr'),dep=T) # for meteR#
#
install.packages("nimble", repos = "http://r-nimble.org", type = "source")#
#
# for gdal stuff, go here for instructions#
# http://tlocoh.r-forge.r-project.org/mac_rgeos_rgdal.html#
# note that i had to use sudo xcodebuild -license at the command line to accept some bs#
#install.packages("rgeos", repos="http://R-Forge.R-project.org", type="source")#
#
install.packages('gdalUtils')
#Current host information: run this bit of code before running any of these functions#Make sure you have RPostgreSQL installedlibrary(RPostgreSQL)#NCEAShost='vegbiendev.nceas.ucsb.edu'dbname='vegbien'user='bien_read'password='T0d0B!en'#
######################Lat/Long from Species Names(s)#species here can be either a single species or a vector of speciesBIENlatlon<-function(species){  library("RPostgreSQL")  # Name the database type that will be used  drv <- dbDriver('PostgreSQL')  # establish connection with database  con <- dbConnect(drv, host=host, dbname=dbname, user=user, password = password)  # set the query  occQuery <- paste("SELECT scrubbed_species_binomial, latitude, longitude,datasource,custodial_institution_codes,collection_code FROM view_full_occurrence_individual WHERE scrubbed_species_binomial in (", paste(shQuote(species, type = "sh"),collapse = ', '), ") AND (is_cultivated = 0 OR is_cultivated IS NULL) AND is_new_world = 1 AND higher_plant_group IS NOT NULL AND (is_geovalid = 1 OR is_geovalid IS NULL) ORDER BY scrubbed_species_binomial;")#
  query = occQuery  #print(query)  # create query to retrieve  df <- dbGetQuery(con, statement = query);#
  dbDisconnect(con)  return(df)#
}################################Species list from country/countries#Currently so slow as to be basically useless#Accepts single countries or vectorsBIENcountry<-function(country){  library("RPostgreSQL")  # Name the database type that will be used  drv <- dbDriver('PostgreSQL')  # establish connection with database  con <- dbConnect(drv, host=host, dbname=dbname, user=user, password = password)  # set the query  occQuery <- paste("SELECT DISTINCT country, scrubbed_species_binomial FROM view_full_occurrence_individual WHERE country in (", paste(shQuote(country, type = "sh"),collapse = ', '), ") AND (is_cultivated = 0 OR is_cultivated IS NULL) AND is_new_world = 1 AND higher_plant_group IS NOT NULL AND (is_geovalid = 1 OR is_geovalid IS NULL) ORDER BY scrubbed_species_binomial;")  #occQuery <- paste("SELECT DISTINCT country, scrubbed_species_binomial FROM view_full_occurrence_individual WHERE country in (", paste(shQuote(country, type = "sh"),collapse = ', '), ") AND (is_cultivated = 0 OR is_cu
ltivated IS NULL) AND is_new_world = 1 AND higher_plant_group IS NOT NULL AND (is_geovalid = 1 OR is_geovalid IS NULL) ORDER BY scrubbed_species_binomial LIMIT 2;") #Limit for testing only#
  query = occQuery  print(query)  # create query to retrieve  df <- dbGetQuery(con, statement = query);#
  dbDisconnect(con)  return(df)#
}############################Occurrences from Genus#Accepts a single Genus or a vector of GeneraBIENgenus<-function(genus){  library("RPostgreSQL")  # Name the database type that will be used  drv <- dbDriver('PostgreSQL')  # establish connection with database  con <- dbConnect(drv, host=host, dbname=dbname, user=user, password = password)  # set the query  occQuery <- paste("SELECT scrubbed_genus, scrubbed_species_binomial, latitude, longitude,datasource,custodial_institution_codes,collection_code FROM view_full_occurrence_individual WHERE scrubbed_genus in (", paste(shQuote(genus, type = "sh"),collapse = ', '), ") AND (is_cultivated = 0 OR is_cultivated IS NULL) AND is_new_world = 1 AND higher_plant_group IS NOT NULL AND (is_geovalid = 1 OR is_geovalid IS NULL) ORDER BY scrubbed_species_binomial;")#
  query = occQuery  #print(query)  # create query to retrieve  df <- dbGetQuery(con, statement = query);#
  dbDisconnect(con)  return(df)#
}#############################Occurrences from Family#Accepts a single Family or a vector of FamiliesBIENfamily<-function(family){  library("RPostgreSQL")  # Name the database type that will be used  drv <- dbDriver('PostgreSQL')  # establish connection with database  con <- dbConnect(drv, host=host, dbname=dbname, user=user, password = password)  # set the query  occQuery <- paste("SELECT scrubbed_family, scrubbed_species_binomial, latitude, longitude,datasource,custodial_institution_codes,collection_code FROM view_full_occurrence_individual WHERE scrubbed_family in (", paste(shQuote(family, type = "sh"),collapse = ', '), ") AND (is_cultivated = 0 OR is_cultivated IS NULL) AND is_new_world = 1 AND higher_plant_group IS NOT NULL AND (is_geovalid = 1 OR is_geovalid IS NULL) ORDER BY scrubbed_species_binomial;")#
  query = occQuery  #print(query)  # create query to retrieve  df <- dbGetQuery(con, statement = query);#
  dbDisconnect(con)  return(df)#
}########################Occurrences from State/Province#Accepts a single State or a vector#Insanely slowBIENstate<-function(state){  library("RPostgreSQL")  # Name the database type that will be used  drv <- dbDriver('PostgreSQL')  # establish connection with database  con <- dbConnect(drv, host=host, dbname=dbname, user=user, password = password)  # set the query  occQuery <- paste("SELECT state_province, scrubbed_species_binomial, latitude, longitude,datasource,custodial_institution_codes,collection_code FROM view_full_occurrence_individual WHERE state_province in (", paste(shQuote(state, type = "sh"),collapse = ', '), ") AND (is_cultivated = 0 OR is_cultivated IS NULL) AND is_new_world = 1 AND higher_plant_group IS NOT NULL AND (is_geovalid = 1 OR is_geovalid IS NULL) ORDER BY scrubbed_species_binomial;")#
  query = occQuery  #print(query)  # create query to retrieve  df <- dbGetQuery(con, statement = query);#
  dbDisconnect(con)  return(df)#
}#############################Traits from species#Accepts a single species or a vector#
BIEN.trait.species<-function(species){  library("RPostgreSQL")  # Name the database type that will be used  drv <- dbDriver('PostgreSQL')  # establish connection with database  con <- dbConnect(drv, host=host, dbname=dbname, user=user, password = password)  # set the query  occQuery <- paste("SELECT * FROM taxon_trait WHERE \"scientificName\" in (", paste(shQuote(species, type = "sh"),collapse = ', '), ") ORDER BY \"scientificName\";")#
  query = occQuery  #print(query)  # create query to retrieve  df <- dbGetQuery(con, statement = query);#
  dbDisconnect(con)  return(df)#
}#############################Traits from trait name#Accepts a single trait or a vector#
BIEN.trait.trait<-function(trait){  library("RPostgreSQL")  # Name the database type that will be used  drv <- dbDriver('PostgreSQL')  # establish connection with database  con <- dbConnect(drv, host=host, dbname=dbname, user=user, password = password)  # set the query  occQuery <- paste("SELECT * FROM taxon_trait WHERE \"measurementType\" in (", paste(shQuote(trait, type = "sh"),collapse = ', '), ") ORDER BY \"scientificName\";")#
  query = occQuery  #print(query)  # create query to retrieve  df <- dbGetQuery(con, statement = query);#
  dbDisconnect(con)  return(df)#
}#############################This function downloads trait data for given speciesBIEN.trait.traitbyspecies<-function(trait,species){  library("RPostgreSQL")  # Name the database type that will be used  drv <- dbDriver('PostgreSQL')  # establish connection with database  con <- dbConnect(drv, host=host, dbname=dbname, user=user, password = password)  # set the query  occQuery <- paste("SELECT * FROM taxon_trait WHERE \"measurementType\" in (", paste(shQuote(trait, type = "sh"),collapse = ', '), ") AND \"scientificName\" in (", paste(shQuote(species, type = "sh"),collapse = ', '), ") ORDER BY \"scientificName\",\"measurementType\";")#
  query = occQuery  #print(query)  # create query to retrieve  df <- dbGetQuery(con, statement = query);#
  dbDisconnect(con)  return(df)#
}#############################This function lists all currently available types of trait data.#This is especially useful if you want to figure out what your trait of interest is titled in this database.BIEN.trait.list<-function(){  library("RPostgreSQL")  # Name the database type that will be used  drv <- dbDriver('PostgreSQL')  # establish connection with database  con <- dbConnect(drv, host=host, dbname=dbname, user=user, password = password)  # set the query  occQuery <- paste("SELECT DISTINCT \"measurementType\",\"measurementUnit\" FROM taxon_trait ORDER BY \"measurementType\";")#
  query = occQuery  #print(query)  # create query to retrieve  df <- dbGetQuery(con, statement = query);#
  dbDisconnect(con)  return(df)#
}#
#############################EXAMPLES#Examples:BIENlatlon# a=BIENlatlon("Abies amabilis")# species_vector<-c("Abies amabilis", "Acer nigrum")# BIENlatlon(species_vector)# # # #Examples: BIENcountry# # BIENcountry("Canada")# country_vector<-c("Canada","United States")# BIENcountry(country_vector)# # #Examples: BIENgenus# # BIENgenus("Abutilon")# genus_vector<-c("Abutilon","Abronia")# BIENgenus(genus_vector)# # #Examples: BIENfamily# BIENfamily("Theaceae")# family_vector<-c("Theaceae","Ericaceae")# BIENfamily(family_vector)# # #Examples: BIENstate# BIENstate("Rhode Island")# state_vector<-c("Rhode Island","Maryland")# BIENstate(state_vector)# # #Examples:BIEN.trait.species# BIEN.trait.species("Poa annua")# species_vector<-c("Poa annua","Juncus trifidus")# BIEN.trait.species(species_vector)# # #Examples: BIEN.trait.trait# BIEN.trait.trait("Height")# trait_vector<-c("Height", "Leaf dry mass")# BIEN.trait.trait(trait_vector)# # #Examples: BIEN.trait.traitbyspecies# BIEN.
trait.traitbyspecies(trait = "Height", species = "Carex capitata")# trait_vector<-c("Height", "Leaf dry mass")# species_vector<-c("Carex capitata","Betula nana")# BIEN.trait.traitbyspecies(trait=trait_vector,species=species_vector)# # #Examples: BIEN.trait.list# BIEN.trait.list()
library(Hmisc)sp=read.table('/Users/ctg/Dropbox/Projects/BIEN/BIEN_R_package temp/Ranges_for_Jesse/SppListForCory.txt')sp[,1]=capitalize(as.character(sp[,1]))sp[,2]=as.character(sp[,2])
sp=apply(sp,1,paste,collapse=' ')
a1=BIENlatlon(sp[1:3])
a1
dim(a1)
head(a1)
a1$scrubbed_species_binomial
head(a1)
a1$latitude
a1=BIENlatlon(sp)
head(a1)
dim(a1)
toss=complete.cases(a1[,c('lat','lon')])
toss=complete.cases(a1[,c('latitude','longitude')])
toss
keep=complete.cases(a1[,c('latitude','longitude')])
a2=a1[keep,]
write.csv('/Users/ctg/Dropbox/Projects/BIEN/BIEN_R_package temp/Ranges_for_Jesse/Bien_Points_From_Cory_8_21_15.csv')
write.csv(a2,'/Users/ctg/Dropbox/Projects/BIEN/BIEN_R_package temp/Ranges_for_Jesse/Bien_Points_From_Cory_8_21_15.csv')
dim(a2)
head(a2)
found.sp=unique(a2$scrubbed_species_binomial)
found.sp
match(found.sp,sp)
missing.sp=sp[-match(found.sp,sp)]
missing.sp
write.csv(missing.sp,'/Users/ctg/Dropbox/Projects/BIEN/BIEN_R_package temp/Ranges_for_Jesse/Missing_Species_From_Cory_8_21_15.csv')
image(NewWorld,axes=F,xlab="",ylab="",col="grey")
library(raster)
NewWorld = raster(paste('/Users/ctg/Documents/BIEN_models/BIENRangeModelingTACC/BackgroundRaster/woGreenland/',"background.img",sep=""))
image(NewWorld,axes=F,xlab="",ylab="",col="grey")
coordinates(a2)=c('longitude','latitude')
points(a2)
head(a2)
a2
NewWorld
plot(a2)
tables(a2$scrubbed_species_binomial)
table(a2$scrubbed_species_binomial)
12.55+4+1.19+4+1.19+8+5.5+13.85+4+11.75+4
801*.575
6*46
4*92*.575
7*86
8*86
422.92-66.03
2398.75/12
3150/12
4368/12
604.60+65+98+165+70.30+276+460.58
604.60+65+98+165+70.30+276+460.58-592
403.70+460.40+299.16+374.70+360.30+233.35
2131.61/12
77+45.69+200+260+364+177 +860
77+45.69+200+260+364+177 +860-1162
11*86
?predict.glm
?expand.gric
?expand.grid
expand.grid(height = seq(60, 80, 5), weight = seq(100, 300, 50),#
            sex = c("Male","Female"))
expand.grid(height = seq(60, 80, 5), weight = seq(100, 300, 50),#
            sex = c("Male","Female"),KEEP.OUT.ATTRS=T)
expand.grid(height = seq(60, 80, 5), weight = seq(100, 300, 50),#
            sex = c("Male","Female"),KEEP.OUT.ATTRS=F)
?fortify
library(popbio)
install.packages('popbio')
library(popbio)
??popbio
install.packages(mra)
install.packages('mra')
?mra
??mra
citation(mra)
citation('mra')
library(gbt)
install.packages('gbt')
install.packages('gbm')
library(gbm)
?gbm
citation(mra)
citation('mra')
?image.plot
?image
?meshplot
?mesh
??mesh
??surf
install.packages('ppmlasso',dep=T)
library(ppmlasso)
??ppmlasso
data(BlueMountains)#
sub.env = BlueMountains$env[BlueMountains$env$Y > 6270 & BlueMountains$env$X > 300,]#
sub.euc = BlueMountains$eucalypt[BlueMountains$eucalypt$Y > 6270 & BlueMountains$eucalypt$X > 300,]#
ppm.form = ~ poly(FC, TMP_MIN, TMP_MAX, RAIN_ANN, degree = 2, raw = TRUE)#
ppm.fit  = ppmlasso(ppm.form, sp.xy = sub.euc, env.grid = sub.env, sp.scale = 1, n.fits = 20)
head(sub.env)
head(sub.euc)
ppm.form
ppm.fit
ai.form  = ~ poly(FC, TMP_MIN, TMP_MAX, RAIN_ANN, degree = 2, raw = TRUE)#
ai.fit   = ppmlasso(ai.form, sp.xy = sub.euc, #
env.grid = sub.env, sp.scale = 1, family = "area.inter", #
r = 2, availability = BlueMountains$availability, n.fits = 20)
print(ppm.fit, out = "model")
diagnose(ppm.fit, which = "smooth", type = "Pearson")
pred.mu = predict(ppm.fit, newdata = sub.env)
pred.mu
ppm.fit
predict.ppmlasso
ppm.fit$formula
?poly
ppm.fit
aa=model.frame(ppm.fit$formula, data = env.grid)
aa=model.frame(ppm.fit$formula, data = sub.env)
head(aa)
dim(model.frame(object$formula, data = newdata))
dim(aa)
dim(env.sub)
dim(sub.env)
str(aa)
dim(aa$poly)
head(aa%poly)
head(aa$poly)
M <- 10000## expected population size at t=1EN <- 100psi <- EN / M
T <- 50
z <- matrix(NA, M, T)z[,1] <- rbinom(M, 1, psi)N <- rep(NA, T)    ## Population sizeN[1] <- sum(z[,1])
s <- array(NA, c(M, 2, T))s[,,1] <- cbind(runif(M), runif(M)) ## Coordinates are similar to individual traitplot(s[z[,1]==1,,1], asp=1) ## Initial spatial distribution
x <- matrix(NA, M, T)x[,1] <- ifelse(z[,1]==0, 0, rlnorm(M))plot(density(x[z[,1]==1,1]))  ## Initial size distribution
alpha0 <- 0alpha1 <- 0.5alpha2 <- 1
## Recruitment is density dependent. Could be local instead of globalgamma0 <- 2gamma1 <- -0.04 # Global effect of population size. Could have a local effect
## Dispersal (simple Gaussian model) depends on size.sigma0 <- -1sigma1 <- -0.1## Dynamics
head(x)
head(s)
s
dim(s)
?rnorm
## Super-population size - must be much larger than the number of individuals ever aliveM <- 10000## expected population size at t=1EN <- 100psi <- EN / M## number of yearsT <- 50## Binary matrix indicating "alive state" of each individual.z <- matrix(NA, M, T)z[,1] <- rbinom(M, 1, psi)N <- rep(NA, T)    ## Population sizeN[1] <- sum(z[,1])#
## Spatial location## Could be modeled using any spatial point process.## Here, assume that individuals are uniformly distributed in space at t=1.s <- array(NA, c(M, 2, T))s[,,1] <- cbind(runif(M), runif(M)) ## Coordinates are similar to individual traitplot(s[z[,1]==1,,1], asp=1) ## Initial spatial distribution## Initial size distributionx <- matrix(NA, M, T)x[,1] <- ifelse(z[,1]==0, 0, rlnorm(M))plot(density(x[z[,1]==1,1]))  ## Initial size distribution#
## Survival depends on size and location.alpha0 <- 0alpha1 <- 0.5alpha2 <- 1#
## Recruitment is density dependent. Could be local instead of globalgamma0 <- 2gamma1 <- -0.04 # Global effect of population size. Could have a local effect#
## Dispersal (simple Gaussian model) depends on size.sigma0 <- -1sigma1 <- -0.1## Dynamicsfor(t in 2:T) {    sigma <- exp(sigma0 + sigma1*x[,t-1]) # dispersal depends on size    s[,,t] <- cbind(rnorm(M, s[,1,t-1], sigma), rnorm(M, s[,2,t-1], sigma)) # Dispersal    phi <- plogis(alpha0 + alpha1*x[,t-1] +                  alpha2*s[,2,t-1]) # survival increases with latitude    a <- rowSums(z[,1:(t-1),drop=FALSE]) == 0 ## Individuals available to be recruited    A <- sum(a) ## Total number of individuals available to be recruited    if(A < 1)        stop("Set M higher")    gamma.U <- exp(gamma0 + gamma1*N[t-1])*N[t-1]    ER <- sum(gamma.U) # Expected number of recruits    gamma <- ER / A    # If alive, survive with prob phi. If not yet alive, recruit with prob gamma    mu <- z[,t-1]*phi + a*gamma    z[,t] <- rbinom(M, 1, mu)    x[,t] <- ifelse(z[,t]==0, 0, x[,t-1]+rlnorm(M, -3, 0.1)) # Stupid growth model    N[t] <- sum(z[,t])}#
## Abundance over timeplot(N, type="o") #, ylim=c(0, 500))
library(lattice)outT <- data.frame(size=as.integer(x), year=factor(rep(1:T, each=M)),                    alive=as.integer(z), easting=as.numeric(s[,1,]),                    northing=as.numeric(s[,2,]))outT <- outT[outT$alive>0,]
densityplot(~ size | year, outT, subset=year %in% 1:36, as.table=TRUE)
plot(with(outT, tapply(size, year, mean)),     ylab="Size")
xyplot(northing ~ easting | year, outT, subset=year %in% 1:36, as.table=TRUE)
4*40*14
1200*9
10800+5300
help(Startup)
options()
ls()
list.files()
setwd('~/Dropbox/Projects/ipms/teachIPMs/Advanced/Range_Models/Exercises/') # set this to your teachIPMs directory
source("Setup_Range_IPMs.r")
d=read.csv('garlic_mustard_data_frame_2_18.csv')mean.envs=read.csv('garlic_mustard_plot_attributes.csv')minSize=4 maxSize=15
d.temp=d[complete.cases(d[,c('sizeNext','size')]),]gr.form= sizeNext~size+PAR+N+Ph.ave+mt.warm.month+mp.maygr.reg=MCMCglmm(gr.form, data=d.temp, verbose=FALSE,burnin=3000, nitt=13000,thin=10)summary(gr.reg)#== save for later usesave(gr.reg,file='Model_Output/AP_growth_v5.post')
posterior.mode(gr.reg$Sol)coda::HPDinterval(gr.reg$Sol, 0.95) autocorr.plot(gr.reg$Sol)plot((gr.reg$Sol)) #== diagnostics #== plot data and predictions pdf('Figures/AP_growth_diagnostics.pdf',h=3.5,w=10)gr.diagnostics(gr.reg,d.temp,random=FALSE)dev.off()system("open Figures/AP_growth_diagnostics.pdf")# map of growth predictionspdf('Figures/AP_growth_map.pdf',h=5,w=10)par(mfrow=c(1,2),oma=c(0,0,2,4))which.subset=mean.envs$habitat==0 # choose closed canopy habitat, since the garlic mustard performs very differently in closed vs open habitat.newdata=data.frame(size=quantile(d$size,.01,na.rm=T), PAR=mean(mean.envs$PAR[which.subset]),N=mean(mean.envs$N[which.subset]),Ph.ave=mean(mean.envs$Ph.ave[which.subset]),sm.t1=mean(mean.envs$sm.t1[which.subset]),values(ne.env)[not.nas,]) # data frame describing the landscape where you're predictinggr.map(gr.reg,d,'AP\nclosed\ncanopy',newdata,zlims=c(0,2))which.subset=mean.envs$habitat==1newdata=data.frame(size=quantile(d$size,.01,na.rm=T), PAR=mean(mean.envs$PAR[which.subset]),N=mean(mean.envs$N[which.subset]),Ph.ave=mean(mean.envs$Ph.ave[which.subset]),sm.t1=mean(mean.envs$sm.t1[which.subset]),values(ne.env)[not.nas,])gr.map(gr.reg,d,'AP\nopen\ncanopy',newdata,zlims=c(0,2))dev.off()system("open Figures/AP_growth_map.pdf")
#== 3. Survival Model -------------------d.sv=d[complete.cases(d[,c('surv')]),]#== checking for correlated predictors, as this model has trouble converging.round(cor(d.sv[,best.var]),2)sv.form=surv~size+PAR+N+Ph.ave+mt.warm.month+mp.maysv.reg=MCMClogit(sv.form, data=d.sv,b0=0, B0=.001,mcmc=5e4,thin=50)summary(sv.reg)save(sv.reg,file='Model_Output/AP_surv_v5.post')  # (load('Model_Output/AP_surv_v3.post'))#== explore output# posterior.mode(sv.reg$Sol)coda::HPDinterval(sv.reg, 0.95)autocorr.plot(sv.reg)plot((sv.reg))
#== diagnostics#== plot data and predictions pdf('Figures/AP_sv_diagnostics.pdf',h=4,w=5)sv.diagnostics(sv.reg,d.sv,form=sv.form)dev.off()system("open Figures/AP_sv_diagnostics.pdf")#== map of surv predictionspdf('Figures/AP_surv_map.pdf',h=5,w=10)par(mfrow=c(1,2),oma=c(0,0,2,4))which.subset=mean.envs$habitat==0newdata=data.frame(size=quantile(d$size,.5,na.rm=T), PAR=mean(mean.envs$PAR[which.subset]),N=mean(mean.envs$N[which.subset]),Ph.ave=mean(mean.envs$Ph.ave[which.subset]),sm.t1=mean(mean.envs$sm.t1[which.subset]),values(ne.env)[not.nas,],surv=1e4) sv.map(sv.reg,'AP\nclosed\ncanopy',newdata,form=sv.form,zlims=c(0,1))which.subset=mean.envs$habitat==1newdata=data.frame(size=quantile(d$size,.5,na.rm=T), PAR=mean(mean.envs$PAR[which.subset]),N=mean(mean.envs$N[which.subset]),Ph.ave=mean(mean.envs$Ph.ave[which.subset]),sm.t1=mean(mean.envs$sm.t1[which.subset]),values(ne.env)[not.nas,],surv=1e4) sv.map(sv.reg,'AP\nopen\ncanopy',newdata,form=sv.form,zlims=c(0,1))dev.off()system("open Figures/AP_surv_map.pdf")
d.seed=d[!is.na(d$fec1) & !is.na(d$size),]seed.form=fec1~size+PAR+Ph.ave+mt.warm.month+mp.mayfec1.reg=MCMCpoisson(seed.form, data=d.seed,b0=0, B0=.001,mcmc=5e4,thin=50)  summary(fec1.reg)#== B. % germinationd.germ=bernoullize(d[!is.na(d$fec2),],col.name1='n.germ.1', col.name0='n.germ.0')germ.form=new.1.0~Ph.ave+light+mt.warm.month+mp.mayfec2.reg=MCMClogit(germ.form, data=d.germ,b0=0, B0=.001,mcmc=5e4,thin=50)  summary(fec2.reg)
#== C. germinant survivald.germ.s=bernoullize(d[!is.na(d$fec3),],col.name1='n.germ.surv.1', col.name0='n.germ.surv.0') # this turns counts of the number of 1s and 0s to a unique row for each 1 and 0, for use with MCMClogitsum.sv.form=new.1.0~Ph.ave+light+mt.warm.month+mp.mayfec3.reg=MCMClogit(sum.sv.form, data=d.germ.s,b0=0, B0=.001,mcmc=5e4,thin=50)summary(fec3.reg)#== D. germinant sized.off=subset(d, (d$Year.planted==d$Year.size) &  is.na(d$flowering))offspr.reg=MCMCglmm(size~1, data=d.off, burnin=3000,nitt=13000,thin=10,verbose=T)summary(offspr.reg)save(fec1.reg,fec2.reg,fec3.reg,offspr.reg, file='Model_Output/AP_fec_v5.post')# (load('Model_Output/AP fec 10-3-12.post'))
#== explore outputplot((fec1.reg))plot((fec2.reg)) plot((fec3.reg))
#== diagnostics ------------------------------------------ #== plot data and predictions pdf('Figures/AP_fec_diagnostics.pdf',h=9,w=6)	fec.diagnostics()dev.off()system("open Figures/AP_fec_diagnostics.pdf")
# map of fec predictionspdf('Figures/AP_fec_map.pdf',h=5,w=15)par(mfrow=c(1,3),oma=c(0,0,2,4)) newdata=data.frame(size=quantile(d$size,.75,na.rm=T), PAR=1.5,N=-1.5,Ph.ave=1.5,light=1.5,values(ne.env)[not.nas,],new.1.0=1e5) seed.map(fec1.reg,'AP',newdata,"seed\nnumber",seed.form=seed.form, zlims=c(0,2000)) sv.map(fec2.reg,'AP',newdata,label="germination\nprobability", form=germ.form) sv.map(fec3.reg,'AP',newdata,label="germinant\nsurvival\nprobability", form=sum.sv.form)dev.off()system("open Figures/AP_fec_map.pdf")
d.fl=d[!is.na(d$flowering) & !is.na(d$size),]fl.form=flowering~size+I(size^2)+I(size^3)+PAR+N+Ph.ave+mp.may+mt.warm.monthfl.reg=MCMClogit(fl.form, data=d.fl,b0=0, B0=.001,mcmc=5e4,thin=50)summary(fl.reg)save(fl.reg,file='Model_Output/AP_flowering_v5.post')# (load('Model_Output/AP_flowering_v2.post'))# explore outputautocorr.plot(fl.reg)plot((fl.reg))
pdf('Figures/AP_fl_diagnostics.pdf',h=6,w=6)	fl.diagnostics(random=FALSE,form=fl.form)dev.off()system("open Figures/AP_fl_diagnostics.pdf")#== map of flowering predictionspdf('Figures/AP_fl_map.pdf',h=5,w=5) newdata=data.frame(size=quantile(d$size,.75,na.rm=T), PAR=1.5,N=-1.5,Ph.ave=1.5,values(ne.env)[not.nas,],flowering=1e4) sv.map(fl.reg,'AP\nopen canopy',newdata,label='flowering\nprobability',form=fl.form)dev.off()system("open Figures/AP_fl_map.pdf")
#== plot all response curves to temperature togetherpdf('Figures/AP_all_response_curves_mt_warm_month.pdf',w=4,h=12)	response.summary(mean.envs,grad='mt.warm.month',lab=letters[1:6],'Mean Temperature Warmest Month')dev.off()system("open Figures/AP_all_response_curves_mt_warm_month.pdf")
#== set up splitting for parallelizingntasks=7#== open or closed habitathabitat=1 #1=open; 0=closed#== managementmanage='' # for bakcward compatibility#manage=.02 # needed for south open and closed#== file labellabel=paste0('NE_habitat',habitat,manage)version='v6'#== specify the environmental conditionsenv.subset=as.matrix(data.frame(unique.env, PAR=ifelse(habitat==1,1.5,-1),N=1.5,Ph.ave=1.5,light=ifelse(habitat==1,1.5,-1)))cell.trick=env.cell.id#== set up indices for cells being useduse=1:nrow(env.subset)(ncells=length(use)) # note that this is #== set up paralleltask.split=chop.tasks(use,ntasks)          #== number of IPM cellsn.matrix = 50b=minSize+c(0:n.matrix)*(maxSize-minSize)/n.matrix #== mesh points (midpoints of the cells)y=0.5*(b[1:n.matrix]+b[2:(n.matrix+1)])#== width of the cellsh=y[2]-y[1]#
#== specify formulas for use in vital rate functionsgr.form=as.formula(paste('~',as.character(gr.reg$Fixed$formula)[3]))sv.form=as.formula(paste('~',paste0(dimnames(sv.reg)[[2]][-1],collapse='+')))seed.form=as.formula(paste('~',paste0(dimnames(fec1.reg)[[2]][-1],collapse='+')))germ.form=as.formula(paste('~',paste0(dimnames(fec2.reg)[[2]][-1],collapse='+')))sum.sv.form=as.formula(paste('~',paste0(dimnames(fec3.reg)[[2]][-1],collapse='+')))fl.form=as.formula(paste('~',paste0(dimnames(fl.reg)[[2]][-1],collapse='+')))offspr.form=as.formula(paste('~',as.character(offspr.reg$Fixed$formula)[3]))#========================================================================#== SET MEAN PARAMETERS#========================================================================gr.params.mean=apply(gr.reg$Sol,2,mean) # growthgr.params.sd=mean(gr.reg$VCV[,'units']) # growth variancesv.params=apply(sv.reg,2,mean)     seed.params=apply(fec1.reg,2,mean)germ.params=apply(fec2.reg,2,mean)sum.sv.params=apply(fec3.reg,2,mean)offspr.params.mean=apply(offspr.reg$Sol,2,mean) # recruit sizeoffspr.param.sd=mean(offspr.reg$VCV[,'units']) # recruit size variancefl.params=apply(fl.reg,2,mean)
registerDoParallel(ntasks)#== GROWTH KERNEL ------------------------------------------------------- p.post.mean=foreach(i = 1:ntasks,.packages="Matrix") %dopar% {		p.mustard.kernel(task.split[[i]])}p.post.mean=unlist(p.post.mean,recursive=F)#== FECUNDITY KERNEL ---------------------------------------------------f.post.mean=foreach(i = 1:ntasks,.packages="Matrix") %dopar% {		f.mustard.kernel(task.split[[i]],manage=manage)}f.post.mean=unlist(f.post.mean,recursive=F)#== SIMULATE DYNAMICS  -------------------------------------------------sim=foreach(i = 1:ntasks,.packages=c("Matrix","IPMpack")) %dopar% { dynamics.mustard(task.split[[i]])}n.lam=unlist(lapply(sim,function(x) x[['lam']]),recursive=FALSE)#== save for later usesave(n.lam,file=paste0('Model_Output/AP_mean_',label,'_pop_stats_',version,'.pred'))#======
?registerDoParallel
??registerDoParallel
library(doParallel)
registerDoParallel(ntasks)#== GROWTH KERNEL ------------------------------------------------------- p.post.mean=foreach(i = 1:ntasks,.packages="Matrix") %dopar% {		p.mustard.kernel(task.split[[i]])}p.post.mean=unlist(p.post.mean,recursive=F)#== FECUNDITY KERNEL ---------------------------------------------------f.post.mean=foreach(i = 1:ntasks,.packages="Matrix") %dopar% {		f.mustard.kernel(task.split[[i]],manage=manage)}f.post.mean=unlist(f.post.mean,recursive=F)#== SIMULATE DYNAMICS  -------------------------------------------------sim=foreach(i = 1:ntasks,.packages=c("Matrix","IPMpack")) %dopar% { dynamics.mustard(task.split[[i]])}n.lam=unlist(lapply(sim,function(x) x[['lam']]),recursive=FALSE)#== save for later usesave(n.lam,file=paste0('Model_Output/AP_mean_',label,'_pop_stats_',version,'.pred'))#======
registerDoParallel(ntasks)#== GROWTH KERNEL ------------------------------------------------------- p.post.mean=foreach(i = 1:ntasks,.packages="Matrix") %dopar% {		p.mustard.kernel(task.split[[i]])}
p.post.mean=unlist(p.post.mean,recursive=F)
f.post.mean=foreach(i = 1:ntasks,.packages="Matrix") %dopar% {		f.mustard.kernel(task.split[[i]],manage=manage)}
sv2
seed2
germ2
sum.sv2
f.mustard.kernel=function(task.split,manage='',random=TRUE){	if(manage=='') manage=1	 post.temp=list(F=lapply(1:length(task.split), function(x) 1))	 for(k in 1:length(task.split)){		 ind=task.split[k]		 tenv=data.frame(t(env.subset[ind,]),new.1.0=1e4)		 offspr.size=offspr2(size=y,mean.params=offspr.params.mean, sd.param=offspr.param.sd, tenv,offspr.form)		 tf=manage*matrix(rep(sv2(y,fl.params,tenv,fl.form,random=random), n.matrix), byrow=T,nrow=n.matrix)		 tsh=matrix(rep(seed2(y,seed.params,tenv,seed.form,random=random), n.matrix), byrow=T,nrow=n.matrix)		 germ=germ2(germ.params,tenv,germ.form,random=random)		 sum.sv=sum.sv2(sum.sv.params,tenv,sum.sv.form)		 F=h*offspr.size*germ*sum.sv*tf*tsh		 post.temp[[k]]=shrink.matrix(F,1e-5)	 }	 post.temp}
f.post.mean=foreach(i = 1:ntasks,.packages="Matrix") %dopar% {		f.mustard.kernel(task.split[[i]],manage=manage)}f.post.mean=unlist(f.post.mean,recursive=F)
sim=foreach(i = 1:ntasks,.packages=c("Matrix","IPMpack")) %dopar% { dynamics.mustard(task.split[[i]])}n.lam=unlist(lapply(sim,function(x) x[['lam']]),recursive=FALSE)#== save for later usesave(n.lam,file=paste0('Model_Output/AP_mean_',label,'_pop_stats_',version,'.pred'))
#== map lambdapdf(paste0('Figures/AP_lambda_map_',label,'_',version,'.pdf'),h=7,w=7) pop.map( unlist(n.lam)[cell.trick], paste0('AP\n',ifelse(habitat==1,'open','closed'), ' habitat'),'lambda',max.val=30)dev.off()system(paste0('open Figures/AP_lambda_map_',label,'_',version,'.pdf'))
pdf(paste0('Figures/AP_lambda_response_curves_',label,'_' ,version,'.pdf'),h=3,w=6) par(mfrow=c(1,2),mar=c(5,4,3,1))plot(values(ne.env)[not.nas,'mt.warm.month'],unlist(n.lam)[cell.trick], pch=19,col= rgb(100,100,100,40,maxColorValue=255), las=1,bty='n',xlab='Mean Temp. Warmest Month',ylab='Lambda')d.tmp=data.frame(lam=c(unlist(n.lam)[cell.trick]),values(ne.env)[not.nas, c('mt.warm.month','mp.may','n.droughts.gs')])m1=gam(lam~s(mt.warm.month),data=d.tmp)xx=seq(min(values(ne.env)[,'mt.warm.month'],na.rm=T),max(values(ne.env)[, 'mt.warm.month'],na.rm=T),by=.05)lines(xx,predict(m1,data.frame(mt.warm.month=xx)),col='red1',lwd=3)plot(values(ne.env)[not.nas,'mp.may'],unlist(n.lam)[cell.trick],pch=19, col=rgb(100,100,100,40,maxColorValue=255), las=1,bty='n',xlab='Mean May Precip.',ylab='Lambda')m1=gam(lam~s(mp.may),data=d.tmp)xx=seq(min(values(ne.env)[,'mp.may'],na.rm=T),max(values(ne.env)[, 'mp.may'],na.rm=T),by=.05)lines(xx,predict(m1,data.frame(mp.may=xx)),col='red1',lwd=3)dev.off()system(paste0('open Figures/AP_lambda_response_curves_',label,'_',version,'.pdf'))
setwd('~/Dropbox/Projects/ipms/teachIPMs/Advanced/Range_Models/Exercises/') # set this to your teachIPMs directory# Note that a number of functions that simplify the following exercise are contained in this file. You don't really need to look at it unless you're going to run these analyses on your own data.source("Setup_Range_IPMs.r")#############################################################################== OUTLINE# 1. Set up data# 2. Growth Model# 3. Survival Model# 4. Fecundity Models# 5. Flowering Probability Model# 6. Summary Plots# 7. Make Mean Kernels# 8. IPM diagnostics ############################################################################# 1. Set up data -----------------------------------------------------------d=read.csv('garlic_mustard_data_frame_2_18.csv')#== mean.envs are the average environmental conditions (over individuals) at each of the 21 common gardens where data were collected.mean.envs=read.csv('garlic_mustard_plot_attributes.csv')minSize=4 # of individuals in the IPMmaxSize=15#== you may later find it useful to reload saved output from the models below if you need to close your R session. But for now, it's commented out.# (load('Model_Output/AP_growth_v5.post'))# (load('Model_Output/AP_surv_v5.post'))# (load('Model_Output/AP_fec_v5.post'))# (load('Model_Output/AP_flowering_v5.post'))# gr.form= as.formula(paste('~',as.character(gr.reg$Fixed$formula)[3]))# sv.form= as.formula(paste('~',paste0(dimnames(sv.reg)[[2]][-1],collapse='+')))# seed.form= as.formula(paste('~',paste0(dimnames(fec1.reg)[[2]][-1],collapse='+')))# germ.form= as.formula(paste('~',paste0(dimnames(fec2.reg)[[2]][-1],collapse='+')))# sum.sv.form= as.formula(paste('~',paste0(dimnames(fec3.reg)[[2]][-1],collapse='+')))# fl.form= as.formula(paste('~',paste0(dimnames(fl.reg)[[2]][-1],collapse='+')))# offspr.form=as.formula(paste('~',as.character(offspr.reg$Fixed$formula)[3]))#
#############################################################################== 2. Growth Model --------------------------------------------------------#== subset the data to just the cases that enter the growth modeld.temp=d[complete.cases(d[,c('sizeNext','size')]),]gr.form= sizeNext~size+PAR+N+Ph.ave+mt.warm.month+mp.maygr.reg=MCMCglmm(gr.form, data=d.temp, verbose=FALSE,burnin=3000, nitt=13000,thin=10)summary(gr.reg)#== save for later usesave(gr.reg,file='Model_Output/AP_growth_v5.post')# (load('Model_Output/Posteriors/AP_growth_v2.post'))#== explore output#== if you're familiar with Bayesian models, check these out. If not the summary() call above tells you what you need to know about the model for this exercise.posterior.mode(gr.reg$Sol)coda::HPDinterval(gr.reg$Sol, 0.95) autocorr.plot(gr.reg$Sol)plot((gr.reg$Sol)) #== diagnostics #== plot data and predictions pdf('Figures/AP_growth_diagnostics.pdf',h=3.5,w=10)gr.diagnostics(gr.reg,d.temp,random=FALSE)dev.off()system("open Figures/AP_growth_diagnostics.pdf")# map of growth predictionspdf('Figures/AP_growth_map.pdf',h=5,w=10)par(mfrow=c(1,2),oma=c(0,0,2,4))which.subset=mean.envs$habitat==0 # choose closed canopy habitat, since the garlic mustard performs very differently in closed vs open habitat.newdata=data.frame(size=quantile(d$size,.01,na.rm=T), PAR=mean(mean.envs$PAR[which.subset]),N=mean(mean.envs$N[which.subset]),Ph.ave=mean(mean.envs$Ph.ave[which.subset]),sm.t1=mean(mean.envs$sm.t1[which.subset]),values(ne.env)[not.nas,]) # data frame describing the landscape where you're predictinggr.map(gr.reg,d,'AP\nclosed\ncanopy',newdata,zlims=c(0,2))which.subset=mean.envs$habitat==1newdata=data.frame(size=quantile(d$size,.01,na.rm=T), PAR=mean(mean.envs$PAR[which.subset]),N=mean(mean.envs$N[which.subset]),Ph.ave=mean(mean.envs$Ph.ave[which.subset]),sm.t1=mean(mean.envs$sm.t1[which.subset]),values(ne.env)[not.nas,])gr.map(gr.reg,d,'AP\nopen\ncanopy',newdata,zlims=c(0,2))dev.off()system("open Figures/AP_growth_map.pdf")############################################################################	#== 3. Survival Model ------------------------------------------------------d.sv=d[complete.cases(d[,c('surv')]),]#== checking for correlated predictors, as this model has trouble converging.round(cor(d.sv[,best.var]),2)sv.form=surv~size+PAR+N+Ph.ave+mt.warm.month+mp.maysv.reg=MCMClogit(sv.form, data=d.sv,b0=0, B0=.001,mcmc=5e4,thin=50)summary(sv.reg)save(sv.reg,file='Model_Output/AP_surv_v5.post')  # (load('Model_Output/AP_surv_v3.post'))#== explore output# posterior.mode(sv.reg$Sol)coda::HPDinterval(sv.reg, 0.95)autocorr.plot(sv.reg)plot((sv.reg)) #== diagnostics#== plot data and predictions pdf('Figures/AP_sv_diagnostics.pdf',h=4,w=5)sv.diagnostics(sv.reg,d.sv,form=sv.form)dev.off()system("open Figures/AP_sv_diagnostics.pdf")#== map of surv predictionspdf('Figures/AP_surv_map.pdf',h=5,w=10)par(mfrow=c(1,2),oma=c(0,0,2,4))which.subset=mean.envs$habitat==0newdata=data.frame(size=quantile(d$size,.5,na.rm=T), PAR=mean(mean.envs$PAR[which.subset]),N=mean(mean.envs$N[which.subset]),Ph.ave=mean(mean.envs$Ph.ave[which.subset]),sm.t1=mean(mean.envs$sm.t1[which.subset]),values(ne.env)[not.nas,],surv=1e4) sv.map(sv.reg,'AP\nclosed\ncanopy',newdata,form=sv.form,zlims=c(0,1))which.subset=mean.envs$habitat==1newdata=data.frame(size=quantile(d$size,.5,na.rm=T), PAR=mean(mean.envs$PAR[which.subset]),N=mean(mean.envs$N[which.subset]),Ph.ave=mean(mean.envs$Ph.ave[which.subset]),sm.t1=mean(mean.envs$sm.t1[which.subset]),values(ne.env)[not.nas,],surv=1e4) sv.map(sv.reg,'AP\nopen\ncanopy',newdata,form=sv.form,zlims=c(0,1))dev.off()system("open Figures/AP_surv_map.pdf")#
#############################################################################== 4. Fecundity Model -----------------------------------------------------#== The fecundity model has multiple components: (A) seeds per plant, (B) germination probability, (C) germinant survival from spring to summer, and (D) germinant size distribution.	#== A. seed numberd.seed=d[!is.na(d$fec1) & !is.na(d$size),]seed.form=fec1~size+PAR+Ph.ave+mt.warm.month+mp.mayfec1.reg=MCMCpoisson(seed.form, data=d.seed,b0=0, B0=.001,mcmc=5e4,thin=50)  summary(fec1.reg)#== B. % germinationd.germ=bernoullize(d[!is.na(d$fec2),],col.name1='n.germ.1', col.name0='n.germ.0')germ.form=new.1.0~Ph.ave+light+mt.warm.month+mp.mayfec2.reg=MCMClogit(germ.form, data=d.germ,b0=0, B0=.001,mcmc=5e4,thin=50)  summary(fec2.reg)#== C. germinant survivald.germ.s=bernoullize(d[!is.na(d$fec3),],col.name1='n.germ.surv.1', col.name0='n.germ.surv.0') # this turns counts of the number of 1s and 0s to a unique row for each 1 and 0, for use with MCMClogitsum.sv.form=new.1.0~Ph.ave+light+mt.warm.month+mp.mayfec3.reg=MCMClogit(sum.sv.form, data=d.germ.s,b0=0, B0=.001,mcmc=5e4,thin=50)summary(fec3.reg)#== D. germinant sized.off=subset(d, (d$Year.planted==d$Year.size) &  is.na(d$flowering))offspr.reg=MCMCglmm(size~1, data=d.off, burnin=3000,nitt=13000,thin=10,verbose=T)summary(offspr.reg)save(fec1.reg,fec2.reg,fec3.reg,offspr.reg, file='Model_Output/AP_fec_v5.post')# (load('Model_Output/AP fec 10-3-12.post'))#== explore outputplot((fec1.reg))plot((fec2.reg)) plot((fec3.reg)) #
#== diagnostics ------------------------------------------------------------#== plot data and predictions pdf('Figures/AP_fec_diagnostics.pdf',h=9,w=6)	fec.diagnostics()dev.off()system("open Figures/AP_fec_diagnostics.pdf")# map of fec predictionspdf('Figures/AP_fec_map.pdf',h=5,w=15)par(mfrow=c(1,3),oma=c(0,0,2,4)) newdata=data.frame(size=quantile(d$size,.75,na.rm=T), PAR=1.5,N=-1.5,Ph.ave=1.5,light=1.5,values(ne.env)[not.nas,],new.1.0=1e5) seed.map(fec1.reg,'AP',newdata,"seed\nnumber",seed.form=seed.form, zlims=c(0,2000)) sv.map(fec2.reg,'AP',newdata,label="germination\nprobability", form=germ.form) sv.map(fec3.reg,'AP',newdata,label="germinant\nsurvival\nprobability", form=sum.sv.form)dev.off()system("open Figures/AP_fec_map.pdf")#############################################################################== 5. Flowering Model -----------------------------------------------------#== flowering probability is a logistic regression, so i just borrow the machinery from the survival functions. d.fl=d[!is.na(d$flowering) & !is.na(d$size),]fl.form=flowering~size+I(size^2)+I(size^3)+PAR+N+Ph.ave+mp.may+mt.warm.monthfl.reg=MCMClogit(fl.form, data=d.fl,b0=0, B0=.001,mcmc=5e4,thin=50)summary(fl.reg)save(fl.reg,file='Model_Output/AP_flowering_v5.post')# (load('Model_Output/AP_flowering_v2.post'))# explore outputautocorr.plot(fl.reg)plot((fl.reg)) # diagnostics  ----------------------------------------------------------#== plot data and predictions pdf('Figures/AP_fl_diagnostics.pdf',h=6,w=6)	fl.diagnostics(random=FALSE,form=fl.form)dev.off()system("open Figures/AP_fl_diagnostics.pdf")#== map of flowering predictionspdf('Figures/AP_fl_map.pdf',h=5,w=5) newdata=data.frame(size=quantile(d$size,.75,na.rm=T), PAR=1.5,N=-1.5,Ph.ave=1.5,values(ne.env)[not.nas,],flowering=1e4) sv.map(fl.reg,'AP\nopen canopy',newdata,label='flowering\nprobability',form=fl.form)dev.off()system("open Figures/AP_fl_map.pdf")##########################################################################== 6. Summary Plots-----------------------------------------------------#== plot all response curves to temperature togetherpdf('Figures/AP_all_response_curves_mt_warm_month.pdf',w=4,h=12)	response.summary(mean.envs,grad='mt.warm.month',lab=letters[1:6],'Mean Temperature Warmest Month')dev.off()system("open Figures/AP_all_response_curves_mt_warm_month.pdf")##########################################################################== 7.Make Mean Kernels--------------------------------------------------#== these loops can be used to calculate the mean predicitons across the region#== set up splitting for parallelizingntasks=7#== open or closed habitathabitat=1 #1=open; 0=closed#== managementmanage='' # for bakcward compatibility#manage=.02 # needed for south open and closed#== file labellabel=paste0('NE_habitat',habitat,manage)version='v6'#== specify the environmental conditionsenv.subset=as.matrix(data.frame(unique.env, PAR=ifelse(habitat==1,1.5,-1),N=1.5,Ph.ave=1.5,light=ifelse(habitat==1,1.5,-1)))cell.trick=env.cell.id#== set up indices for cells being useduse=1:nrow(env.subset)(ncells=length(use)) # note that this is #== set up paralleltask.split=chop.tasks(use,ntasks)          #== number of IPM cellsn.matrix = 50b=minSize+c(0:n.matrix)*(maxSize-minSize)/n.matrix #== mesh points (midpoints of the cells)y=0.5*(b[1:n.matrix]+b[2:(n.matrix+1)])#== width of the cellsh=y[2]-y[1]#
#== specify formulas for use in vital rate functionsgr.form=as.formula(paste('~',as.character(gr.reg$Fixed$formula)[3]))sv.form=as.formula(paste('~',paste0(dimnames(sv.reg)[[2]][-1],collapse='+')))seed.form=as.formula(paste('~',paste0(dimnames(fec1.reg)[[2]][-1],collapse='+')))germ.form=as.formula(paste('~',paste0(dimnames(fec2.reg)[[2]][-1],collapse='+')))sum.sv.form=as.formula(paste('~',paste0(dimnames(fec3.reg)[[2]][-1],collapse='+')))fl.form=as.formula(paste('~',paste0(dimnames(fl.reg)[[2]][-1],collapse='+')))offspr.form=as.formula(paste('~',as.character(offspr.reg$Fixed$formula)[3]))#========================================================================#== SET MEAN PARAMETERSgr.params.mean=apply(gr.reg$Sol,2,mean) # growthgr.params.sd=mean(gr.reg$VCV[,'units']) # growth variancesv.params=apply(sv.reg,2,mean)     seed.params=apply(fec1.reg,2,mean)germ.params=apply(fec2.reg,2,mean)sum.sv.params=apply(fec3.reg,2,mean)offspr.params.mean=apply(offspr.reg$Sol,2,mean) # recruit sizeoffspr.param.sd=mean(offspr.reg$VCV[,'units']) # recruit size variancefl.params=apply(fl.reg,2,mean)#========================================================================#== BUILD IPMSregisterDoParallel(ntasks)#== GROWTH KERNEL  p.post.mean=foreach(i = 1:ntasks,.packages="Matrix") %dopar% {		p.mustard.kernel(task.split[[i]])}p.post.mean=unlist(p.post.mean,recursive=F)#== FECUNDITY KERNEL f.post.mean=foreach(i = 1:ntasks,.packages="Matrix") %dopar% {		f.mustard.kernel(task.split[[i]],manage=manage)}f.post.mean=unlist(f.post.mean,recursive=F)#== SIMULATE DYNAMICS sim=foreach(i = 1:ntasks,.packages=c("Matrix","IPMpack")) %dopar% { dynamics.mustard(task.split[[i]])}n.lam=unlist(lapply(sim,function(x) x[['lam']]),recursive=FALSE)#== save for later usesave(n.lam,file=paste0('Model_Output/AP_mean_',label,'_pop_stats_',version,'.pred'))#==========================================================================#==========================================================================#== 8. IPM diagnostics  ---------------------------------------------------#== map lambdapdf(paste0('Figures/AP_lambda_map_',label,'_',version,'.pdf'),h=7,w=7) pop.map( unlist(n.lam)[cell.trick], paste0('AP\n',ifelse(habitat==1,'open','closed'), ' habitat'),'lambda',max.val=30)dev.off()system(paste0('open Figures/AP_lambda_map_',label,'_',version,'.pdf'))#== plot lambda vs envpdf(paste0('Figures/AP_lambda_response_curves_',label,'_' ,version,'.pdf'),h=3,w=6) par(mfrow=c(1,2),mar=c(5,4,3,1))plot(values(ne.env)[not.nas,'mt.warm.month'],unlist(n.lam)[cell.trick], pch=19,col= rgb(100,100,100,40,maxColorValue=255), las=1,bty='n',xlab='Mean Temp. Warmest Month',ylab='Lambda')d.tmp=data.frame(lam=c(unlist(n.lam)[cell.trick]),values(ne.env)[not.nas, c('mt.warm.month','mp.may','n.droughts.gs')])m1=gam(lam~s(mt.warm.month),data=d.tmp)xx=seq(min(values(ne.env)[,'mt.warm.month'],na.rm=T),max(values(ne.env)[, 'mt.warm.month'],na.rm=T),by=.05)lines(xx,predict(m1,data.frame(mt.warm.month=xx)),col='red1',lwd=3)plot(values(ne.env)[not.nas,'mp.may'],unlist(n.lam)[cell.trick],pch=19, col=rgb(100,100,100,40,maxColorValue=255), las=1,bty='n',xlab='Mean May Precip.',ylab='Lambda')m1=gam(lam~s(mp.may),data=d.tmp)xx=seq(min(values(ne.env)[,'mp.may'],na.rm=T),max(values(ne.env)[, 'mp.may'],na.rm=T),by=.05)lines(xx,predict(m1,data.frame(mp.may=xx)),col='red1',lwd=3)dev.off()system(paste0('open Figures/AP_lambda_response_curves_',label,'_',version,'.pdf'))
1554/2
40*.34
